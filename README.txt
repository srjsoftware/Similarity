The latest version of this package can be downloaded from
https://sourceforge.net/projects/gtknn/

Copyright (C) 2015 by Wisllay Vitrio

All files in this package may be modified and/or distributed according to
the GNU GPL, version 2, June 1991, that should have been distributed with
this package.


Description:

The following code is a parallel  kNN implementation that uses GPUs for the
high dimensional data in text classification. 
You can use it to classify documents using kNN or to generate meta-features
based on the distances between a query document and its k nearest neigbors
[1].



Compiling instructions:

You need to have a nvidia graphics card and
the CUDA library installed in your machine. 
For more information, go to https://developer.nvidia.com/cuda-downloads

Compile our GT-kNN implementation:
$ make

This will generate the gtknn executable called gtknn.


Run:
In order to run, you can use the following command:
$ ./gtknn <training_file> <test_file> <k> <cosine | l2 | l1> <output_classifications_file> <output_distances_file> <number of GPUs>


where

-> training_file and test_file are on the format:
docid class termid1 termfrequency1 termid2 termfrequency2 ...
There is a training and test example in the data directory. There is also a
script that converts from the svmlight/libsvm files to our format.
Be aware that we use the term frequencies of each document as features.
-> k is number of nearest nighbors used in kNN.
-> cosine, l2 and l1 are the similarity/distance measures you can choose .
-> output_classifications_file is the file that contains the classification
of each test file accoring to kNN. Macro-F1, Micro-F1 and other evaluation 
measures can be extracted from it using the sofware, in the "evaluate" directory.
-> output_distances_file contains the distances of the choosen measure. Each
line corresponds to a query document and the columns are the distances (i.e. the 
first column is the distance between the query document and its nearest neighbor).
The meta-features described in [1] are generated by manipulating the training file 
(splitting it in classes) and the output_distance_file. 



[1] Efficient and Scalable MetaFeature-based Document Classification using
Massively Parallel Computing, SIGIR 2015
